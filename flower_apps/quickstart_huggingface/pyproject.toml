[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "huggingface_example"
version = "1.0.0"
description = "Federated Learning with Hugginface Transformers and Flower (Quickstart Example)"
license = "Apache-2.0"
authors = [
    { name = "The Flower Authors", email = "hello@flower.ai" },
    { name = "Kaushik Amar Das", email = "kaushik.das@iiitg.ac.in" },
]
dependencies = [
    "flwr[simulation]>=1.21.0",
    "flwr-datasets>=0.5.0",
    "torch>=2.8.0",
    "transformers>=4.30.0,<5.0",
    "evaluate>=0.4.0,<1.0",
    "datasets>=2.0.0, <3.0",
    "scikit-learn>=1.3.1, <2.0",
    "markupsafe==2.1.3"
]

[tool.uv.sources]
torch = [
    { index = "pytorch-cpu" },
]
torchvision = [
    { index = "pytorch-cpu" },
]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "flwrlabs"

[tool.flwr.app.components]
serverapp = "huggingface_example.server_app:app"
clientapp = "huggingface_example.client_app:app"

[tool.flwr.app.config]
num-server-rounds = 3
model-name = "prajjwal1/bert-tiny"
fraction-fit = 1.0
fraction-evaluate = 0.1

[tool.flwr.federations]
default = "local-simulation"

[tool.flwr.federations.local-simulation]
options.num-supernodes = 100

[tool.flwr.federations.local-simulation-gpu]
options.num-supernodes = 100
options.backend.client-resources.num-cpus = 4 # each ClientApp assumes to use 4CPUs
options.backend.client-resources.num-gpus = 0.0 # at most 4 ClientApp will run in a given GPU (lower it to increase parallelism)

[tool.flwr.federations.local-deployment]
address = "0.0.0.0:9093"
root-certificates = "/data/certs/server.crt" # hardcoded for now.
